{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f343090",
   "metadata": {},
   "source": [
    "# Desgning a Classification Model for the Bank-Notes Dataset Using Different Activation Functions and Varying Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0465979",
   "metadata": {},
   "source": [
    "## Submitted By: Ms. Sidra Mehtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604af1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing  the necessary modules\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from random import random\n",
    "from csv import reader\n",
    "from math import exp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7ee928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def loadCsv(filename):\n",
    "        trainSet = []\n",
    "        \n",
    "        lines = csv.reader(open(filename, 'r'))\n",
    "        next(lines)\n",
    "        dataset = list(lines)\n",
    "        for i in range(len(dataset)):\n",
    "                for j in range(5):\n",
    "                        #print(\"DATA {}\".format(dataset[i]))\n",
    "                        dataset[i][j] = float(dataset[i][j])\n",
    "                trainSet.append(dataset[i])\n",
    "        return trainSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681e4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(dataset):\n",
    "        minmax = list()\n",
    "        stats = [[min(column), max(column)] for column in zip(*dataset)]\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba870c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize(dataset, minmax):\n",
    "        for row in dataset:\n",
    "                for i in range(len(row)-1):\n",
    "                        row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20840b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to float\n",
    "def column_to_float(dataset, column):\n",
    "        for row in dataset:\n",
    "                try:\n",
    "                        row[column] = float(row[column])\n",
    "                except ValueError:\n",
    "                        print(\"Error with row\",column,\":\",row[column])\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbec143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to integer\n",
    "def column_to_int(dataset, column):\n",
    "        class_values = [row[column] for row in dataset]\n",
    "        unique = set(class_values)\n",
    "        lookup = dict()\n",
    "        for i, value in enumerate(unique):\n",
    "                lookup[value] = i\n",
    "        for row in dataset:\n",
    "                row[column] = lookup[row[column]]\n",
    "        return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6465b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min and max values for each column\n",
    "\n",
    " \n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "        dataset_split = list()\n",
    "        dataset_copy = list(dataset)\n",
    "        fold_size = int(len(dataset) / n_folds)\n",
    "        for i in range(n_folds):\n",
    "                fold = list()\n",
    "                while len(fold) < fold_size:\n",
    "                        index = randrange(len(dataset_copy))\n",
    "                        fold.append(dataset_copy.pop(index))\n",
    "                dataset_split.append(fold)\n",
    "        return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7205ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy percentage\n",
    "def accuracy_met(actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "                if actual[i] == predicted[i]:\n",
    "                        correct += 1\n",
    "        return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d468b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate an algorithm using a cross validation split\n",
    "def run_algorithm(dataset, algorithm, n_folds, *args):\n",
    "        \n",
    "        folds = cross_validation_split(dataset, n_folds)\n",
    "        #for fold in folds:\n",
    "                #print(\"Fold {} \\n \\n\".format(fold))\n",
    "        scores = list()\n",
    "        Accuracy = list()\n",
    "        for fold in folds:\n",
    "                #print(\"Test Fold {} \\n \\n\".format(fold))\n",
    "                train_set = list(folds)\n",
    "                train_set.remove(fold)\n",
    "                train_set = sum(train_set, [])\n",
    "                test_set = list()\n",
    "                for row in fold:\n",
    "                        row_copy = list(row)\n",
    "                        test_set.append(row_copy)\n",
    "                        row_copy[-1] = None\n",
    "                predicted = algorithm(train_set, test_set, *args)\n",
    "                actual = [row[-1] for row in fold]\n",
    "                accuracy = accuracy_met(actual, predicted)\n",
    "                cm = confusion_matrix(actual, predicted)\n",
    "                print('\\n'.join([''.join(['{:5}'.format(item) for item in row]) for row in cm]))\n",
    "                #confusionmatrix = np.matrix(cm)\n",
    "                FP = cm.sum(axis=0) - np.diag(cm)\n",
    "                FN = cm.sum(axis=1) - np.diag(cm)\n",
    "                TP = np.diag(cm)\n",
    "                TN = cm.sum() - (FP + FN + TP)\n",
    "                print('False Positives\\n {}'.format(FP))\n",
    "                print('False Negetives\\n {}'.format(FN))\n",
    "                print('True Positives\\n {}'.format(TP))\n",
    "                print('True Negetives\\n {}'.format(TN))\n",
    "                TPR = TP/(TP+FN)\n",
    "                print('Sensitivity \\n {}'.format(TPR))\n",
    "                TNR = TN/(TN+FP)\n",
    "                print('Specificity \\n {}'.format(TNR))\n",
    "                Precision = TP/(TP+FP)\n",
    "                print('Precision \\n {}'.format(Precision))\n",
    "                Recall = TP/(TP+FN)\n",
    "                print('Recall \\n {}'.format(Recall))\n",
    "                Acc = (TP+TN)/(TP+TN+FP+FN)\n",
    "                print('Áccuracy \\n{}'.format(Acc))\n",
    "                Fscore = 2*(Precision*Recall)/(Precision+Recall)\n",
    "                print('FScore \\n{}'.format(Fscore))\n",
    "                k=cohen_kappa_score(actual, predicted)\n",
    "                print('Çohen Kappa \\n{}'.format(k))\n",
    "                scores.append(accuracy)\n",
    "                Accuracy.append(Acc)\n",
    "        return Accuracy,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "039c5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "        activation = weights[-1]\n",
    "        for i in range(len(weights)-1):\n",
    "                activation += weights[i] * inputs[i]\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d16a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer neuron activation\n",
    "# def transfer_sigmoid(activation):\n",
    "#        return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "def transfer_leaky_relu(activation):\n",
    "    if activation > 0:\n",
    "        return activation\n",
    "    else:\n",
    "        return 0.01*activation\n",
    "    \n",
    "# def transfer_tanh(activation):\n",
    "#    t=(np.exp(activation)-np.exp(-activation))/(np.exp(activation)+np.exp(-activation))\n",
    "#    return t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d9ca504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "        inputs = row\n",
    "        for layer in network:\n",
    "                new_inputs = []\n",
    "                for neuron in layer:\n",
    "                        activation = activate(neuron['weights'], inputs)\n",
    "                        neuron['output'] = transfer_leaky_relu(activation)\n",
    "                        new_inputs.append(neuron['output'])\n",
    "                inputs = new_inputs\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "637d0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "# def transfer_derivative_sigmoid(output):\n",
    "#        return output * (1.0 - output)\n",
    "    \n",
    "def transfer_derivative_leaky_relu(output):\n",
    "     return 0.01 if output < 0 else 1\n",
    "    \n",
    "# def transfer_derivative_tanh(output): \n",
    "#    return 1-output**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d92aab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "        for i in reversed(range(len(network))):\n",
    "                layer = network[i]\n",
    "                errors = list()\n",
    "                if i != len(network)-1:\n",
    "                        for j in range(len(layer)):\n",
    "                                error = 0.0\n",
    "                                for neuron in network[i + 1]:\n",
    "                                        error += (neuron['weights'][j] * neuron['delta'])\n",
    "                                errors.append(error)\n",
    "                else:\n",
    "                        for j in range(len(layer)):\n",
    "                                neuron = layer[j]\n",
    "                                errors.append(expected[j] - neuron['output'])\n",
    "                for j in range(len(layer)):\n",
    "                        neuron = layer[j]\n",
    "                        neuron['delta'] = errors[j] * transfer_derivative_leaky_relu(neuron['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72f6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "        for i in range(len(network)):\n",
    "                inputs = row[:-1]                \n",
    "                if i != 0:\n",
    "                        inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "                for neuron in network[i]:\n",
    "                        for j in range(len(inputs)):\n",
    "                                temp = l_rate * neuron['delta'] * inputs[j] + mu * neuron['prev'][j]\n",
    "                                \n",
    "                                neuron['weights'][j] += temp\n",
    "                                #print(\"neuron weight{} \\n\".format(neuron['weights'][j]))\n",
    "                                neuron['prev'][j] = temp\n",
    "                        temp = l_rate * neuron['delta'] + mu * neuron['prev'][-1]\n",
    "                        neuron['weights'][-1] += temp\n",
    "                        neuron['prev'][-1] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aba64418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "        for epoch in range(n_epoch):\n",
    "                for row in train:\n",
    "                        outputs = forward_propagate(network, row)\n",
    "                        #print(network)\n",
    "                        expected = [0 for i in range(n_outputs)]\n",
    "                        expected[row[-1]] = 1\n",
    "                        #print(\"expected row{}\\n\".format(expected))\n",
    "                        backward_propagate_error(network, expected)\n",
    "                        update_weights(network, row, l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9527b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "        network = list()\n",
    "        hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)], 'prev':[0 for i in range(n_inputs+1)]} for i in range(n_hidden)]        \n",
    "        network.append(hidden_layer)\n",
    "        hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)], 'prev':[0 for i in range(n_inputs+1)]} for i in range(n_hidden)]        \n",
    "        network.append(hidden_layer)\n",
    "        output_layer = [{'weights':[random() for i in range(n_hidden + 1)],'prev':[0 for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "        network.append(output_layer)\n",
    "        print(network)\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6c8cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "        outputs = forward_propagate(network, row)\n",
    "        return outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a687527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
    "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
    "        n_inputs = len(train[0]) - 1\n",
    "        n_outputs = len(set([row[-1] for row in train]))\n",
    "        network = initialize_network(n_inputs, n_hidden, n_outputs)\n",
    "        train_network(network, train, l_rate, n_epoch, n_outputs)\n",
    "        #print(\"network {}\\n\".format(network))\n",
    "        predictions = list()\n",
    "        for row in test:\n",
    "                prediction = predict(network, row)\n",
    "                predictions.append(prediction)\n",
    "        return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77a3f4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'weights': [0.17615879778364407, 0.7589167742520844, 0.7392069166892044, 0.5805470101101052, 0.4511136377957703], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.1494295452398231, 0.5039464408606785, 0.5284814960517538, 0.13506734851795632, 0.7614081860479278], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.9888681835793595, 0.21318079766159026, 0.6225476674268445, 0.48040695734353067, 0.11840708649100551], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.8872547085591933, 0.6983487476145435, 0.225027830064511, 0.6352626423450226, 0.8290270470300498], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.05003101053142989, 0.17208366606210723, 0.11613748391157386, 0.5632603481367554, 0.5030167815653596], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.6599045536241351, 0.3078631641139429, 0.32764095816192507, 0.7737891750041515, 0.8217239626147195], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.8222080663992034, 0.22026646945301764, 0.743050651434886, 0.280172569160838, 0.6256524546816344], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.8612227614303887, 0.2690742656673415, 0.7187653073551493, 0.3792765365773795, 0.1216563606994927], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.3470232348102419, 0.11340058036760736, 0.8986096514014973, 0.1432790434450103, 0.5740082043485562], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.3470016723675662, 0.09182010386086414, 0.9987784035743005, 0.2999861636535822, 0.24895221195621509], 'prev': [0, 0, 0, 0, 0]}]]\n",
      "  137    6\n",
      "    0  131\n",
      "False Positives\n",
      " [0 6]\n",
      "False Negetives\n",
      " [6 0]\n",
      "True Positives\n",
      " [137 131]\n",
      "True Negetives\n",
      " [131 137]\n",
      "Sensitivity \n",
      " [0.95804196 1.        ]\n",
      "Specificity \n",
      " [1.         0.95804196]\n",
      "Precision \n",
      " [1.         0.95620438]\n",
      "Recall \n",
      " [0.95804196 1.        ]\n",
      "Áccuracy \n",
      "[0.97810219 0.97810219]\n",
      "FScore \n",
      "[0.97857143 0.97761194]\n",
      "Çohen Kappa \n",
      "0.9562043795620438\n",
      "[[{'weights': [0.5296269733441361, 0.36175683163978134, 0.07831774010535164, 0.9257618293116034, 0.3720571989842185], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.7200510996459284, 0.6913022416983619, 0.09386127948495882, 0.3288215866210549, 0.007962849104687586], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.8881921047108448, 0.9589513983478465, 0.11221210176022733, 0.9233322650459617, 0.7909860211699676], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.7241627040753184, 0.12589992289364604, 0.9272347008465601, 0.27107981894286703, 0.09107301145048952], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.5766440154659536, 0.7253743076900668, 0.475585598978698, 0.4187210838180927, 0.9338974087966286], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.3010952092581941, 0.21939252788371888, 0.30267144403698343, 0.13312392722024802, 0.6000914164522895], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.10986847560962076, 0.2405814917014778, 0.8972318577365, 0.27449387718704954, 0.019986109811157893], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.5388329421798466, 0.9448336402337725, 0.261744882712022, 0.12607324423855149, 0.7088727735262625], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.7449157638361875, 0.06907478462473493, 0.9774723242536107, 0.3631424497422032, 0.5554870355413712], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.8044607693192589, 0.5073548606380018, 0.5808227958561007, 0.6190456696460244, 0.4454869827807867], 'prev': [0, 0, 0, 0, 0]}]]\n",
      "  151    0\n",
      "  123    0\n",
      "False Positives\n",
      " [123   0]\n",
      "False Negetives\n",
      " [  0 123]\n",
      "True Positives\n",
      " [151   0]\n",
      "True Negetives\n",
      " [  0 151]\n",
      "Sensitivity \n",
      " [1. 0.]\n",
      "Specificity \n",
      " [0. 1.]\n",
      "Precision \n",
      " [0.55109489        nan]\n",
      "Recall \n",
      " [1. 0.]\n",
      "Áccuracy \n",
      "[0.55109489 0.55109489]\n",
      "FScore \n",
      "[0.71058824        nan]\n",
      "Çohen Kappa \n",
      "0.0\n",
      "[[{'weights': [0.1322111573500393, 0.074346899341591, 0.5792832981193552, 0.6766184559398997, 0.8268437327166523], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.48407148451797477, 0.8009945962446159, 0.7673814470728092, 0.36509114420855315, 0.2923431706411227], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.15560457743040845, 0.7951157494018565, 0.8331301915624558, 0.4056400665481371, 0.9767049223259483], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.1451435556244538, 0.29529242714404536, 0.6869549661829168, 0.6388720691478551, 0.9531113654984892], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.5372792702342215, 0.009698375461110187, 0.8152265745620081, 0.1325773848556454, 0.7469885987185967], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.942291772982568, 0.10114309534079435, 0.030366203034060013, 0.4319538965713895, 0.6792493046989979], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.27606278608386625, 0.37014411694132465, 0.40613380525841647, 0.4619877044355444, 0.09918666236671703], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.7791397425339686, 0.6460830174694423, 0.6973646953745949, 0.8121876794253704, 0.8317651384407699], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.5873913179306305, 0.5304439701741811, 0.7632029157600432, 0.5510291849889107, 0.7829263134570688], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.5682239823713892, 0.9686040927086944, 0.35641801954870644, 0.47391394391438635, 0.6974722537783788], 'prev': [0, 0, 0, 0, 0]}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-318515d133a9>:37: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Precision = TP/(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  151    0\n",
      "  123    0\n",
      "False Positives\n",
      " [123   0]\n",
      "False Negetives\n",
      " [  0 123]\n",
      "True Positives\n",
      " [151   0]\n",
      "True Negetives\n",
      " [  0 151]\n",
      "Sensitivity \n",
      " [1. 0.]\n",
      "Specificity \n",
      " [0. 1.]\n",
      "Precision \n",
      " [0.55109489        nan]\n",
      "Recall \n",
      " [1. 0.]\n",
      "Áccuracy \n",
      "[0.55109489 0.55109489]\n",
      "FScore \n",
      "[0.71058824        nan]\n",
      "Çohen Kappa \n",
      "0.0\n",
      "[[{'weights': [0.9275350630900715, 0.6217922064647944, 0.10554042877522518, 0.9519684937426224, 0.8719968360562562], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.11640322042148132, 0.04057852861539768, 0.7040543505079936, 0.4223945876938293, 0.7272772367764718], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.2534908105250847, 0.625773437289816, 0.8983627317255044, 0.9155832682227135, 0.6169523480152537], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.4149352861665432, 0.35874422113546567, 0.7539069638858403, 0.34123597622677826, 0.7981918357256077], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.23805992033281276, 0.6096457728668733, 0.1443734769227446, 0.3414971804099921, 0.11350154050725014], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.513043404908474, 0.5430339175667197, 0.6259047425347517, 0.8944169531835956, 0.757475120651921], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.12148216348289664, 0.5827809946363023, 0.4802559755541813, 0.20921414631037882, 0.6316025095719721], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.9530942378544165, 0.39724458542906926, 0.22780441567075616, 0.24835389357514792, 0.9748747123026004], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.3290484894559942, 0.24517228293809112, 0.6767975200809943, 0.742986071640007, 0.3695498667107905], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.6514284817364461, 0.6631778159979715, 0.9367690324319012, 0.43199120045158557, 0.39885796265321904], 'prev': [0, 0, 0, 0, 0]}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-318515d133a9>:37: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Precision = TP/(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  157    0\n",
      "  117    0\n",
      "False Positives\n",
      " [117   0]\n",
      "False Negetives\n",
      " [  0 117]\n",
      "True Positives\n",
      " [157   0]\n",
      "True Negetives\n",
      " [  0 157]\n",
      "Sensitivity \n",
      " [1. 0.]\n",
      "Specificity \n",
      " [0. 1.]\n",
      "Precision \n",
      " [0.5729927       nan]\n",
      "Recall \n",
      " [1. 0.]\n",
      "Áccuracy \n",
      "[0.5729927 0.5729927]\n",
      "FScore \n",
      "[0.72853828        nan]\n",
      "Çohen Kappa \n",
      "0.0\n",
      "[[{'weights': [0.12041025289467455, 0.48827770297803685, 0.266456707118058, 0.12521482370705328, 0.011942322374289605], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.41461703262457617, 0.7990091445015655, 0.6524016192152049, 0.9413497014564688, 0.45879718487022203], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.37701746573464134, 0.5020399898132009, 0.8149426675476388, 0.9179583799504564, 0.15428865680173232], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.524603425160236, 0.10573512276099672, 0.2545883209913006, 0.46443128136208256, 0.8108713748589025], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.7046824748521638, 0.7929380827594594, 0.2283666099438949, 0.6955078645854621, 0.9916502684751451], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.5441235363771263, 0.24947436885653373, 0.42297022720609934, 0.15890489267012853, 0.1790527205353637], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.6624033245380987, 0.07605732064708826, 0.5363585422592563, 0.5578565594578243, 0.16094845664208657], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.37568325240427813, 0.021573197194324933, 0.21686297973562163, 0.23566288347840825, 0.04045561653213481], 'prev': [0, 0, 0, 0, 0]}], [{'weights': [0.5156620496856035, 0.1902392856799502, 0.5040294057921656, 0.611867238980209, 0.9982095475253014], 'prev': [0, 0, 0, 0, 0]}, {'weights': [0.07722080683645383, 0.3981631083747522, 0.4649469414285826, 0.5670126277498019, 0.04834746857723082], 'prev': [0, 0, 0, 0, 0]}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-318515d133a9>:37: RuntimeWarning: invalid value encountered in true_divide\n",
      "  Precision = TP/(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  156    3\n",
      "    0  115\n",
      "False Positives\n",
      " [0 3]\n",
      "False Negetives\n",
      " [3 0]\n",
      "True Positives\n",
      " [156 115]\n",
      "True Negetives\n",
      " [115 156]\n",
      "Sensitivity \n",
      " [0.98113208 1.        ]\n",
      "Specificity \n",
      " [1.         0.98113208]\n",
      "Precision \n",
      " [1.         0.97457627]\n",
      "Recall \n",
      " [0.98113208 1.        ]\n",
      "Áccuracy \n",
      "[0.98905109 0.98905109]\n",
      "FScore \n",
      "[0.99047619 0.98712446]\n",
      "Çohen Kappa \n",
      "0.9776034003596534\n"
     ]
    }
   ],
   "source": [
    "# Test Backprop on Seeds dataset\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'Bank_Note_Authentication.csv'\n",
    "dataset = loadCsv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "        column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "column_to_int(dataset, len(dataset[0])-1)\n",
    "# normalize input variables\n",
    "minmax = minmax(dataset)\n",
    "normalize(dataset, minmax)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "mu=0.001\n",
    "# n_epoch = 200\n",
    "n_epoch = 150\n",
    "n_hidden = 4\n",
    "Accuracy, scores = run_algorithm(dataset, back_propagation, n_folds, l_rate, n_epoch, n_hidden)\n",
    "\n",
    "# print()\n",
    "#print(score.0)\n",
    "#print('Scores: %s' % scores)\n",
    "#print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d5870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
